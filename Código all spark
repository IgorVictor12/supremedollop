import cv2
import numpy as np
import time
import sys
from scipy.spatial.distance import cdist # Para calcular a distância entre os pontos

class ProfessionalVisionSystem:
    def __init__(self, camera_index=0):
        self.cap = cv2.VideoCapture(camera_index)
        
        # Configura a câmera para resolução máxima disponível
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
        
        if not self.cap.isOpened():
            raise ValueError("Não foi possível abrir a câmera.")
        
        # Armazena as dimensões reais que a câmera conseguiu abrir
        self.frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        print(f"Câmera iniciada com resolução: {self.frame_width}x{self.frame_height}")

        # --- PARÂMETROS DE CALIBRAÇÃO DE LENTE (Estimativa para remover Olho de Peixe) ---
        # Em um cenário real, isso é obtido fotografando um tabuleiro de xadrez.
        # Estes valores são genéricos para "alisar" a imagem.
        # NOTA: Estes valores (cx, cy) devem ser baseados na resolução REAL da câmera (self.frame_width / 2, self.frame_height / 2)
        center_x = self.frame_width / 2
        center_y = self.frame_height / 2
        
        # Usando uma estimativa de distância focal (f) de 1000 para uma distorção leve
        f = 1000.0 
        self.mtx = np.array([[f, 0, center_x],
                             [0, f, center_y],
                             [0, 0, 1]])
        self.dist = np.array([-0.2, 0.1, 0, 0]) # Coeficientes de distorção (k1, k2, p1, p2)

        # --- INICIALIZAÇÃO DA SUPER RESOLUÇÃO (IA) ---
        # Tenta carregar o modelo de IA se disponível, senão usa algoritmo matemático
        self.sr = cv2.dnn_superres.DnnSuperResImpl_create()
        self.use_ai_upscale = False
        try:
            # Se você tiver o arquivo 'EDSR_x4.pb', coloque na mesma pasta e descomente abaixo
            # self.sr.readModel("EDSR_x4.pb")
            # self.sr.setModel("edsr", 4) 
            # self.use_ai_upscale = True
            pass
        except:
            print("Modelo de IA não encontrado. Usando redimensionamento Bicúbico de Alta Qualidade.")

    def capture_and_stack(self, num_frames=60):
        """
        Captura múltiplos frames e faz a média para eliminar ruído (granulado).
        Processamento 100% em memória RAM.
        """
        print(f"\n--- [CAPTURA INICIADA] ---")
        print(f"Capturando {num_frames} frames para Super-Empilhamento...")
        frames = []
        
        # Janela de progresso
        progress_window = "Progresso da Captura"
        cv2.namedWindow(progress_window, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(progress_window, 400, 100)
        
        for i in range(num_frames):
            ret, frame = self.cap.read()
            if ret:
                # Converte para float32 para evitar estouro de valor na soma
                frames.append(frame.astype(np.float32))
                
                # Exibe o progresso
                progress_img = np.zeros((100, 400), dtype=np.uint8)
                progress_text = f"Capturando frame: {i+1}/{num_frames}"
                cv2.putText(progress_img, progress_text, (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                cv2.imshow(progress_window, progress_img)
                cv2.waitKey(1) # Essencial para o OpenCV atualizar a janela
            else:
                print(f"Falha ao capturar frame {i}")
        
        cv2.destroyWindow(progress_window)

        if not frames:
            return None

        print("Fundindo imagens para eliminar ruído...")
        # Calcula a média de todos os frames (Empilhamento)
        stack_img = np.mean(frames, axis=0)
        
        # Converte de volta para uint8 (imagem padrão 0-255)
        return stack_img.astype(np.uint8)

    def correct_lens_distortion(self, image):
        """
        Remove a distorção 'Olho de Peixe' para deixar a imagem reta.
        """
        h, w = image.shape[:2]
        # Otimiza a matriz da câmera para o novo tamanho
        newcameramtx, roi = cv2.getOptimalNewCameraMatrix(self.mtx, self.dist, (w,h), 1, (w,h))
        
        # Desfaz a distorção
        dst = cv2.undistort(image, self.mtx, self.dist, None, newcameramtx)
        
        # Recorta a imagem para remover as bordas pretas curvas geradas pela correção
        x, y, w, h = roi
        if w > 0 and h > 0:
            dst = dst[y:y+h, x:x+w]
        return dst

    def enhance_image_quality(self, image):
        """
        Aplica pós-processamento profissional: CLAHE, Nitidez e Upscaling.
        """
        # print("Aplicando pós-processamento avançado...") # REMOVIDO
        
        # 1. Upscaling (Aumentar resolução e qualidade)
        if self.use_ai_upscale:
            # Via Inteligência Artificial (Lento, mas perfeito)
            print("Usando Upscale de IA...")
            image = self.sr.upsample(image)
        else:
            # Via Bicúbica (Rápido e muito bom com imagem empilhada)
            # Aumenta 2x o tamanho para análise de precisão
            # print("Usando Upscale Bicúbico...") # REMOVIDO
            
            # --- ALGORITMO REMOVIDO A PEDIDO ---
            # image = cv2.resize(image, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)
            pass # Mantém a imagem original se a IA não estiver ativa

        # 2. Redução de Ruído Cromático (Suaviza cores sem perder bordas)
        # Como já fizemos empilhamento, usamos um valor baixo aqui para não borrar
        # print("Reduzindo ruído cromático...") # REMOVIDO
        
        # --- ALGORITMO REMOVIDO A PEDIDO ---
        # image = cv2.fastNlMeansDenoisingColored(image, None, 3, 3, 7, 21)

        # 3. CLAHE (Equalização de Histograma Adaptativo)
        # Melhora a iluminação local (tira sombras, reduz estouro de branco)
        # print("Aplicando CLAHE para balanço de iluminação...") # REMOVIDO
        
        # --- ALGORITMO REMOVIDO A PEDIDO ---
        # lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        # l, a, b = cv2.split(lab)
        # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        # cl = clahe.apply(l)
        # limg = cv2.merge((cl,a,b))
        # image = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)

        # 4. Sharpening (Aumento de Nitidez)
        # print("Aplicando Nitidez...") # REMOVIDO
        
        # --- ALGORITMO REMOVIDO A PEDIDO ---
        # kernel_sharpening = np.array([[-1,-1,-1], 
        #                               [-1, 9,-1],
        #                               [-1,-1,-1]])
        # image = cv2.filter2D(image, -1, kernel_sharpening)

        return image

    def analyze_scene(self, image):
        """
        Realiza a segmentação baseada no esquema de cores HLS definido,
        com agrupamento de contornos próximos para evitar contagem dupla de objetos tremidos.
        """
        print("Analisando cena (Isolamento e Agrupamento de Pontos)...")
        hls = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)
        result_viz = image.copy()

        # --- ESQUEMA DE CORES (Baseado nas nossas calibrações anteriores) ---
        # Ajustado para a imagem pós-processada (que tem mais contraste)
        
        # 1. Mancha de Óleo (Preto/Escuro)
        # L < 60
        mask_mancha = cv2.inRange(hls, (0, 0, 0), (180, 60, 255))

        # 2. Alga (Cinza/Desaturado)
        # S < 65 (mas não preto)
        mask_alga_raw = cv2.inRange(hls, (0, 0, 0), (180, 255, 65))
        mask_alga = cv2.bitwise_and(mask_alga_raw, cv2.bitwise_not(mask_mancha))

        # 3. Navio (Colorido/Saturado)
        # S > 65
        mask_navio = cv2.inRange(hls, (0, 0, 65), (180, 255, 255))
        mask_navio = cv2.bitwise_and(mask_navio, cv2.bitwise_not(mask_mancha)) # Garante que não é preto

        # --- Dicionário de Detecção ---
        detections = {
            "Mancha de Oleo": (mask_mancha, (0, 0, 255)), # Vermelho
            "Alga": (mask_alga, (0, 255, 255)),           # Amarelo
            "Navio": (mask_navio, (255, 0, 0))            # Azul
        }

        final_count = {"Mancha de Oleo": 0, "Alga": 0, "Navio": 0}

        # Iterar sobre cada tipo de detecção
        for label, (mask, color) in detections.items():
            # Morfologia para limpar ruído (traços de latitude/longitude finos)
            kernel = np.ones((3,3), np.uint8)
            mask_clean = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel) # Remove ruído pequeno
            mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_CLOSE, kernel) # Fecha buracos no objeto

            contours, _ = cv2.findContours(mask_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            valid_objects_data = [] # Para armazenar (center, radius, contour_area) dos objetos válidos

            for cnt in contours:
                area = cv2.contourArea(cnt)
                if area > 400: # Filtro de Área
                    (x,y), radius = cv2.minEnclosingCircle(cnt)
                    center = (int(x),int(y))
                    radius = int(radius)
                    
                    perimeter = cv2.arcLength(cnt, True)
                    if perimeter == 0: continue
                    circularity = 4 * np.pi * (area / (perimeter * perimeter))
                    
                    if circularity > 0.5: # Filtro de Circularidade
                        valid_objects_data.append({"center": center, "radius": radius, "area": area, "contour": cnt})

            # --- Agrupamento de Objetos Próximos ---
            if not valid_objects_data:
                continue

            # Raio de agrupamento: considere 1.5x o raio médio dos objetos. Ajuste conforme necessário.
            # Se seus objetos na simulação são todos de tamanho parecido, um valor fixo pode ser melhor.
            # Aqui, vamos usar um valor adaptativo, mas você pode definir um 'cluster_distance_threshold = 50' (por exemplo)
            # para 50 pixels de distância.
            
            avg_radius = np.mean([obj['radius'] for obj in valid_objects_data]) if valid_objects_data else 0
            cluster_distance_threshold = max(50, int(avg_radius * 1.5)) # Mínimo de 50 pixels, ou 1.5x o raio médio
            print(f"  {label}: Raio médio = {avg_radius:.2f}, Threshold de agrupamento = {cluster_distance_threshold} pixels")

            # Lista para guardar os objetos já agrupados
            grouped_objects = []
            
            # Percorre todos os objetos válidos para tentar agrupá-los
            for obj1_idx, obj1 in enumerate(valid_objects_data):
                if obj1.get('grouped', False): # Se já foi agrupado, pule
                    continue

                current_group = [obj1]
                obj1['grouped'] = True # Marca como agrupado

                for obj2_idx, obj2 in enumerate(valid_objects_data):
                    if obj1_idx == obj2_idx or obj2.get('grouped', False): # Não compare consigo mesmo ou já agrupado
                        continue

                    dist = np.linalg.norm(np.array(obj1['center']) - np.array(obj2['center']))
                    
                    if dist < cluster_distance_threshold:
                        current_group.append(obj2)
                        obj2['grouped'] = True # Marca como agrupado
                
                grouped_objects.append(current_group)

            # Para cada grupo, determine um único objeto representativo (ex: pelo centro médio e raio máximo)
            for group in grouped_objects:
                if not group: continue

                # Calcula o centro médio do grupo
                mean_center_x = int(np.mean([obj['center'][0] for obj in group]))
                mean_center_y = int(np.mean([obj['center'][1] for obj in group]))
                mean_center = (mean_center_x, mean_center_y)

                # Pega o raio do maior objeto no grupo, ou um raio médio
                max_radius = int(max([obj['radius'] for obj in group]))
                
                # Desenha o objeto agrupado
                cv2.circle(result_viz, mean_center, max_radius + 5, color, 3) 
                cv2.putText(result_viz, label, (mean_center[0]-40, mean_center[1]-max_radius-15), 
                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 3) 
                final_count[label] += 1

        print(f"--- Relatório Final: {final_count} ---")
        return result_viz, final_count

    def process_and_analyze(self):
        """
        Função chamada pelo ESPAÇO.
        Executa toda a pipeline de processamento e exibe o resultado.
        """
        
        # 1. Captura e Empilhamento (Stacking)
        # Tira 60 fotos e funde em uma única imagem de alta qualidade
        super_image = self.capture_and_stack(num_frames=60)
        
        if super_image is None:
            print("Erro na captura.")
            return

        # 2. Correção Física (Lente)
        rectilinear_image = self.correct_lens_distortion(super_image)

        # 3. Melhoria de Qualidade (Upscale + Luz + Nitidez)
        final_high_res = self.enhance_image_quality(rectilinear_image)

        # 4. Análise Computacional
        analyzed_image, report = self.analyze_scene(final_high_res)

        # 5. Exibição e Salvamento Final
        timestamp = int(time.time())
        filename = f"resultado_analise_pro_{timestamp}.png"
        
        cv2.imwrite(filename, analyzed_image)
        print(f"Imagem de alta fidelidade salva como: {filename}")
        
        # Redimensiona apenas para exibir na tela (a salva está em full HD/4K)
        display_h = 800
        ratio = display_h / analyzed_image.shape[0]
        display_dim = (int(analyzed_image.shape[1] * ratio), display_h)
        display_img = cv2.resize(analyzed_image, display_dim)
        
        # Adiciona o relatório à imagem de exibição
        y_offset = 40
        for key, value in report.items():
            text = f"{key}: {value}"
            cv2.putText(display_img, text, (20, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            y_offset += 40

        # Mostra o resultado em uma NOVA janela
        result_window_name = f"Resultado da Analise {timestamp}"
        cv2.imshow(result_window_name, display_img)
        print("Análise concluída. Exibindo em nova janela.")
        print("--- Pressione [ESPAÇO] para nova análise ou [ESC] para sair ---")


    def start_interactive_mode(self):
        """
        MODO PRINCIPAL: Exibe o feed ao vivo em modo janela.
        Aguarda o ESPAÇO para disparar a análise.
        """
        
        window_name = "Live Feed - Pressione ESPACO para Analisar | ESC para Sair"
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)

        print("--- Sistema de Visão Profissional Iniciado ---")
        print("Feed ao vivo em MODO JANELA (redimensionavel).")
        print("Pressione [ESPACO] para capturar e analisar a cena.")
        print("Pressione [ESC] para sair.")

        # Variáveis para cálculo de FPS
        start_time = time.time()
        frame_counter = 0
        fps_display = "FPS: Calculando..."

        while True:
            ret, frame = self.cap.read()
            if not ret:
                print("Erro ao ler frame. Tentando reconectar...")
                time.sleep(1)
                continue

            # Redimensiona o frame para exibição em tempo real se for muito grande
            display_frame = frame.copy()
            if display_frame.shape[1] > 1280: # Se largura maior que 1280, redimensiona
                scale_factor = 1280 / display_frame.shape[1]
                display_frame = cv2.resize(display_frame, (1280, int(display_frame.shape[0] * scale_factor)))


            # --- Cálculo de FPS ---
            frame_counter += 1
            elapsed_time = time.time() - start_time
            if elapsed_time > 1.0: # Atualiza a cada 1 segundo
                fps_display = f"FPS: {frame_counter / elapsed_time:.2f}"
                frame_counter = 0
                start_time = time.time()
            # --- Fim Cálculo de FPS ---

            # Adiciona texto de ajuda no frame
            display_text = "AO VIVO | [ESPACO] = Analisar | [ESC] = Sair"
            cv2.putText(display_frame, display_text, (20, 50), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3, cv2.LINE_AA)

            # Adiciona texto de FPS no frame
            cv2.putText(display_frame, fps_display, (20, 100), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3, cv2.LINE_AA)

            cv2.imshow(window_name, display_frame) # Exibe o frame redimensionado

            key = cv2.waitKey(1) & 0xFF

            if key == 27: # Tecla ESC
                print("Saindo do sistema...")
                break
            
            elif key == 32: # Tecla ESPAÇO
                print("\n[TRIGGER] Tecla ESPACO pressionada!")
                self.process_and_analyze()
                

        # Limpeza final
        self.cap.release()
        cv2.destroyAllWindows()


if __name__ == "__main__":
    try:
        # Se tiver várias câmeras, tente alterar o índice para 1 ou 2
        system = ProfessionalVisionSystem(camera_index=0)
        
        # Inicia o modo interativo em vez do 'run' linear
        system.start_interactive_mode() 
        
    except ValueError as e:
        print(f"ERRO: {e}")
        print("Verifique se a câmera está conectada e o índice (camera_index) está correto.")
        sys.exit(1)
    except Exception as e:
        print(f"Um erro inesperado ocorreu: {e}")
        sys.exit(1)
